---
title: "EAEA Analyses"
output:
  html_document:
    df_print: paged
  pdf_document: default
author: Isabella Kahhale
date: 02/23/2022
---

The following graphs/tables combine data from the following samples: 

- Recruited on 6/8/21, 5 participants (no IRI data)
- Recruited on 1/31/22,	20 participants
- Recruited on 2/21/22,	21 participants

3 folks are excluded for not meeting either a) qualtrics attention checks, b) EA task/video attention checks, or c) both. 

*Total n* = 47
```{r read in data, echo= FALSE, eval = TRUE, warning = FALSE, message=FALSE}

#uncomment and use this version if we need to first calcuate the summary EA stuff. the dat below already has those as cols. also would need to run second code chunk and change from eval = FALSE 

dat <- read.csv("/Users/isabellakahhale/OneDrive/Isabella/Research/EA-EA/Data/participants/Masterdata_03292022.csv")
library(dplyr)
library(tidyverse)
library(Hmisc)
library(ggplot2)
require(reshape2)
library(corrplot)
library(data.table)
library(stats)
library(xtable)
library(knitr)


  
```


```{r Digit Span, eval = FALSE, echo = FALSE}

meanfwd <- mean(dat$MaxFwd, na.rm = TRUE)
sdfwd<- sd(dat$MaxFwd, na.rm = TRUE)

#how many people have a maxfwd value that is greater than the mean of hte dataset plus 2 times the standard deviatoin
length(which(dat$MaxFwd > meanfwd+(2*sdfwd)))

#how many people have a maxfwd value that is less than the mean of hte dataset plus 2 times the standard deviatoin
length(which(dat$MaxFwd < meanfwd-(2*sdfwd)))

meanrev <- mean(dat$MaxRev, na.rm = TRUE)
sdrev <- sd(dat$MaxRev, na.rm = TRUE)

#how many people have a maxfwd value that is greater than the mean of hte dataset plus 2 times the standard deviatoin
length(which(dat$MaxRev > meanrev+(2*sdrev)))

#how many people have a maxfwd value that is less than the mean of hte dataset plus 2 times the standard deviatoin
length(which(dat$MaxRev < meanrev-(2*sdrev)))
```

```{r Combine MSSD data}

mssd <- read.csv("/Users/isabellakahhale/OneDrive/Isabella/Research/EA-EA/Analysis/mssd03242022.csv")

mssd <- rename(mssd, subID = partID)

dat <- left_join(dat, mssd, by = "subID")
```




```{r determine exlcusion ns, eval=FALSE, echo= FALSE}
nrow(dat)
#filter out people who don't get all 4 qualtics attention correct
dat <- dat %>% 
  filter(meets_survey_score_threshold ==TRUE) # attn score = 4 

nrow(dat)

#number of people who do'nt pass 14/16 threshold 
length(which(dat$meets_task_score_threshold == "FALSE")) 

#filter out those people
dat <- dat %>% 
  filter(meets_task_score_threshold ==TRUE)
nrow(dat)

#sample is 33

#people who didn't move the slider bar 

length(which(dat$NoSliderMove == "1")) 
dat <- dat %>% 
  filter(NoSliderMove ==0)
nrow(dat)
#sample is 31

# people who didn't complete digit span task -- look at total digit span column, and make sure its not NA
length(which(is.na(dat$Total)))
dat <- dat %>% 
  filter(!is.na(dat$Total))
nrow(dat)

# exclude based on having digit span forward or backwards  more than 2 sds outside of the mean 
length(which(dat$MaxFwd> meanfwd+(2*sdfwd)))

dat <- dat %>% 
  filter(dat$MaxFwd <= meanfwd+(2*sdfwd))
nrow(dat)

length(which(dat$MaxRev> meanrev+(2*sdrev)))

dat <- dat %>% 
  filter(dat$MaxRev <= meanrev+(2*sdrev))

nrow(dat)

```


```{r calculate average Empathic Accuracy, eval = FALSE, echo = FALSE}
#attach(dat)

#### sliderbar / EA correlations  ####

# does EA correlate with self-reported empathy (IRI)

ea_colnames <- colnames(select(dat, starts_with("EA")))

#replace 999..0 values in the main dat dataframe as NA for all the EA videos 
dat <- dat %>% mutate_at(vars(ea_colnames), ~na_if(.,999.0))

#compute average EA for each PS 

ea_dat <- dat %>% select(starts_with("EA_")) %>% 
  transmute(avg_EA = rowMeans(.,na.rm = TRUE)) %>% 
  as.data.frame()

#assign that average EA vector back to original DF 
dat$avg_EA <- ea_dat$avg_EA

#take NaN values and make then NA
dat$avg_EA[is.nan(dat$avg_EA)]<-NA

# look at means for each video
dat %>% 
  select(starts_with("EA_")) %>% 
  colMeans(na.rm = TRUE) %>% 
  t() %>% 
  kable()

#Videos 129_2 and 147_2 have low EA -- still true. 

# calcualte average without those 2 videos and see if correlations are different

 
select_vars <- c("EA_120_4", "EA_128_2", "EA_167_2", "EA_173_6", "EA_174_3", "EA_181_2")

#avg_EA_select is teh average EA for each ps without the 2 bad videos     
dat <-  dat %>% mutate(avg_EA_select = rowMeans(select(., select_vars), na.rm = TRUE))     

dat %>% 
  select(avg_EA, avg_EA_select) %>% 
 # t() %>% 
  head %>% 
  kable()

#get rid of 1 Na value       
dat$avg_EA_select[is.nan(dat$avg_EA_select)]<-NA

#write.csv(dat, "completedata.csv")

#saveRDS(dat, "knitdata.rds")
```


## Distributions of Key Variables.

```{r distribution of key variables, message=FALSE, warning = FALSE, echo = FALSE, eval = TRUE}
#### distribution of adversity measures, aggression, and antisoical measures   ####

melt.dat <- dat %>% dplyr::select(
  ResponseId,
  PSS_total,
  QUIC_unpredict_total,
  IRI_total,
  BPAQ_Anger,
  #BPAQ_Physical,
  #BPAQ_Hostility,
  #BPAQ_Verbal,
  BCE_total,
  income, 
  SRGS_total,
 # SRDS_total,
#  SRPSF_Tot,
 # MASQ_AA,
  #MASQ_AD,
  #MASQ_GDA, 
  #MASQ_GDD,
  MAES_SUM,
  #MAES_MULTI,
  avg_EA_select
) %>%
  pivot_longer(-ResponseId, names_to = "variable", values_to = "value") 

ggplot(data = melt.dat, aes(x = value)) + 
stat_density() + 
facet_wrap(~variable, scales = "free")
```

## adversity, psychopathology, and empathic accuracy correlation matrix.

variable avg_EA is the average empathic accuracy across all 8 videos; variable avg_EA_select is the average empathic accuracy for 6 videos, excluding the 2 videos with low overall accuracy (videos 129_2 and 147_2). 
```{r adversity and psychopathology correlation matrix, message=FALSE, warning = FALSE, echo = FALSE, eval = TRUE}
####  ####

dat %>% select(
    PSS_total,
    QUIC_unpredict_total,
    IRI_total,
    BPAQ_Anger,
    BPAQ_Physical,
    BPAQ_Hostility,
    BPAQ_Verbal,
    BCE_total,
    income, 
    SRGS_total,
    SRDS_total,
    SRPSF_Tot,
    MASQ_AA,
    MASQ_AD,
    MASQ_GDA, 
    MASQ_GDD,
    MAES_SUM,
    MAES_MULTI,
    avg_EA,
    avg_EA_select
) %>% 
    cor(use="complete.obs") %>% 
  corrplot(insig = "p-value")
```

## adversity, psychopathology, and empathic accuracy correlation table.
```{r adversity and psychopathology correlation table, message=FALSE, warning = FALSE, echo = FALSE, eval = TRUE}

#save correlation table to corr.dat and write as csv if interested 
corr.dat <- dat %>% select(
  #  PSS_total,
    QUIC_unpredict_total,
    IRI_total,
  #  IRI_EC,
  #  IRI_PT,
  #  IRI_PD,
    BPAQ_Anger,
    BPAQ_Physical,
    BPAQ_Hostility,
   # BPAQ_Verbal,
    BCE_total,
    income, 
   #SRGS_total,
    SRDS_total,
   # SRPSF_Tot,
    MASQ_AA,
  #  MASQ_AD,
  #  MASQ_GDA, 
  #  MASQ_GDD,
    MAES_SUM,
  #  MAES_MULTI,
  #  avg_EA,
    avg_EA_select
) %>% 
  rename(IRI = IRI_total,
         Anger = BPAQ_Anger,
         Hostility = BPAQ_Hostility,
         Phys.Agg = BPAQ_Physical,
         BCE = BCE_total,
         EmpAcc = avg_EA_select,
         Delin. = SRDS_total,
         Anx.Arousal = MASQ_AA,
         Unpredict. = QUIC_unpredict_total,
         Mltx = MAES_SUM) %>%  
  #filter(avg_EA_select>0) %>% 
    cor(use="complete.obs")  
  
  
  kable(., caption = "Correlation Table for Key Variables", format = "markdown")

  #trying other corrplot things

corrplot(cor(corr.dat),
   method = "color", 
   addCoef.col="green", 
   order = "AOE", 
   number.cex=7/ncol(corr.dat))

#write.csv(corr.dat, "correlation_table.csv")

corrplot(corr.dat, method = 'circle', type = 'lower', insig='blank',
         addCoef.col ='black', number.cex=8/ncol(corr.dat), order = 'AOE', diag=FALSE)
```
some comparisons of correlation values with the the previous version that included 1 persons negative empathic accuracy score: 


```{r correlation matrix w p values}
corr <- dat %>% select(
    IRI_total,
    BPAQ_Hostility,
    SRDS_total,
    MAES_SUM,
    QUIC_unpredict_total,
    avg_EA_select)
    
    
  table <- rcorr(as.matrix(corr),type="pearson")
table

```

### Empathic accuracy and other variables

- avg_EA_select and IRI_PT here is 0.219, previously .01
- avg_EA_select and QUIC_unpredictability here is -0.47, previously -0.551 
- avg_EA_select and BPAQ_physical here is -0.08, previously -0.28
- avg_EA_select and BPAQ_hostility here is -0.39, previously -0.36
- avg_EA_select and MAES correlated at -0.39 here, previously -0.33 
- avg_EA_select and self-reported delinquency (SRDS) at -0.19 here, previously -0.56
- avg_EA_select and several MASQ mood/anxiety/depression subscales generally highly correlated (~0.3) across both 

### Antisociality and other variables

- self reported delinquency (SRDS) is highly correlated with all BPAQ scales in both versions
- self report psychopathy (SRP-SF) is also highly correalted with BPAQ scales, and correlates highly with self-reported delinquency 

### Childhood experiences and other variables

- MAES sum and multi (n of different types of abuse) are highly correlated with QUIC_unpredictability in both sets
- Belevolent Childhood Experiences (BCE) correlated with IRI_IEC at 0.38 here, previously 0.40
- SRGS (Stress related growth) -- highly negatively correlated w perceived stress scale, QUIC_unpredictability, BPAQ Anger, 
BPAQ hostility, BCE, a bunch of the MASQ mood qnnrs 


## Scatterplots displaying associations between average empathic accuracy and other key variables

Higher empathic accuracy scores denote greater accuracy. These plots were computed using the empathic accuracy "select" variable, which did not consider the two videos with low overall accuracy (videos 129_2 and 147_2).

```{r Plot scatter EA association with other vars, echo=FALSE, warning = FALSE, message = FALSE}

#found this solution to making long here
#https://stackoverflow.com/questions/7570319/the-right-way-to-plot-multiple-y-values-as-separate-lines-with-ggplot2

long.dat.ea <- dat %>% select(
#  PSS_total,
#  QUIC_unpredict_total,
  IRI_total,
  BPAQ_Anger,
  #BPAQ_Physical,
  #BPAQ_Hostility,
  #BPAQ_Verbal,
  BCE_total,
  income, 
  SRGS_total,
#  SRDS_total,
#  SRPSF_Tot,
#  MASQ_AA,
#  MASQ_AD,
#  MASQ_GDA, 
#  MASQ_GDD,
  MAES_SUM,
 # MAES_MULTI,
  avg_EA_select
) %>% 
  rename(IRI = IRI_total,
         Anger = BPAQ_Anger,
         Benevolent_Childhood_Experiences = BCE_total,
         Stress_Related_Growth = SRGS_total,
         Maltreatment = MAES_SUM) %>%  
  pivot_longer(-avg_EA_select, names_to = "variable", values_to = "value") 

  
long.dat.ea %>%  
  filter(avg_EA_select >0) %>%  # this excludes the negative EA_avg_select value
  ggplot(aes(avg_EA_select, value, colour = variable)) + geom_point() + facet_wrap(vars(variable), scales = "free") + theme(legend.position="none") + 
  xlab("Average Empathic Accuracy") +labs(color = "Legend")

#  scale_x_continuous(breaks = c(0.00, 0.25, 0.50, 0.75), labels = c("0.00", "0.25", "0.50", "0.75"))

long.dat.ea <- dat %>% 
  select(IRI_total,
         IRI_PT,
         IRI_EC,
         IRI_PD,
         BPAQ_Hostility,
         SRDS_total,
         MAES_SUM,
         QUIC_unpredict_total,
         avg_EA_select,
         avg_EA,
         income)%>% 
  rename(IRI = IRI_total,
         Hostility = BPAQ_Hostility, 
         Delinquency = SRDS_total,
         Childhood_Unpredictability = QUIC_unpredict_total,
         Empathic_Accuracy_select = avg_EA_select,
         Empathic_Accuracy = avg_EA,
         Childhood_Maltreatment = MAES_SUM) %>%  
  pivot_longer(-IRI, names_to = "variable", values_to = "value") 



    table <- rcorr(as.matrix(long.dat.ea),type="pearson")
table




# look at same associations but instead of comparing to emphatic accuracy, compare to IRI subscales
long.dat.ea %>%  
  #filter(avg_EA_select >0) %>%  # this excludes the negative EA_avg_select value
  ggplot(aes(IRI, value, colour = variable)) + geom_point() + facet_wrap(vars(variable), scales = "free") + theme(legend.position="none") + 
  xlab("IRI Total") +labs(color = "Legend")

```

## lm plots displaying associations between average empathic accuracy and other key variables

```{r Plot lm EA association with other vars, echo=FALSE, warning = FALSE, message = FALSE}

long.dat.ea %>%  
  filter(avg_EA_select >0) %>%  # this excludes the negative EA_avg_select value.
  ggplot(aes(avg_EA_select, value, colour = variable)) + geom_smooth() + facet_wrap(vars(variable), scales = "free") + theme(legend.position="none") + xlab("Average Empathic Accuracy")

```


```{r initial linear models}

# use digit span as covariate (this is Total variable)

mod1 <- lm(IRI_total ~ MAES_SUM + QUIC_unpredict_total + Total, data = dat)

mod1 <- lm(IRI_EC ~ MAES_SUM + QUIC_unpredict_total + Total, data = dat)

mod1 <- lm(IRI_PT ~ MAES_SUM + QUIC_unpredict_total + Total, data = dat)

summary(mod1)
```

```{r MSSD Analysis}

head(dat$X120_4_mssd)

#Take the average MSSD across all 8 videos/columns nd store in new variable

#gather the mssd colnames (this INCLUDES practices)
mssd_colnames <- colnames(select(dat, ends_with("mssd")))

#compute average MSSD for each PS 

mssd_dat <- dat %>% 
  select(mssd_colnames) %>%
  mutate(avg_mssd = rowMeans(.,na.rm = TRUE)) %>% 
  rowwise() %>% 
  mutate(sd_mssd= sd(c_across(X120_4_mssd:practice_mssd))) %>% 
  as.data.frame()

#assign that average mssd vector back to original DF 
dat$avg_mssd <- mssd_dat$avg_mssd
dat$sd_mssd <- mssd_dat$sd_mssd



#take NaN values and make then NA
#dat$avg_EA[is.nan(dat$avg_EA)]<-NA

# look at means for each video
dat %>% 
  select(mssd_colnames) %>% 
  colMeans(na.rm = TRUE) %>% 
  t() %>% 
  kable()

#Videos 129_2 and 147_2 are the ones w low EA. these 2 don't have the lowest mssd 

# calcuate average mssd across whole dataset 
overall_avg_mssd <- mean(dat$avg_mssd)
overall_avg_mssd # ~ mean is about 5. median is about 4
overall_sd_mssd <- mean(dat$sd_mssd)
overall_sd_mssd # ~ mean is about 5, median is about 2

length(which(dat$avg_mssd < (overall_avg_mssd-sd(dat$avg_mssd)))) # how many people are 1 standard deviation outside of the sample average mssd -- 1 person. 
            
length(which(dat$sd_mssd < (overall_sd_mssd-sd(dat$sd_mssd))))   ## how many people are 1 standard deviation outside othe mean for the standard deviaiton of mssd value. sd of sd_mssd is 6 so it's greater than the mean.         


```

